---
title: Reduce size
jupyter: python3
---

```{python}
#| id: TgTHkAbO1uFL
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: TgTHkAbO1uFL
#| outputId: 4f2d8bde-38ca-4f6a-ae76-f5f47186ed33
from google.colab import drive
drive.mount('/content/drive')
```

```{python}
#| id: IKB398kPso-p
#| id: IKB398kPso-p
!pip install moviepy

!pip3 install imageio==2.4.1

!pip install --upgrade imageio-ffmpeg
```

Import the required libraries

```{python}
#| id: 6ls9F3ad7Ron
#| id: 6ls9F3ad7Ron
import cv2
import os
import numpy as np
import pandas as pd
from google.colab.patches import cv2_imshow
from numpy import genfromtxt
from PIL import Image
import os
import moviepy.editor as mp
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
```



Define the video path and a path to save the reduced-size frames

```{python}
#| id: ZQcH8BAa601E
#| id: ZQcH8BAa601E
video_path = '/content/drive/MyDrive/Track Buckling Project/230306 - Third Huckleberry Trail Test/GoPro/GX011334.MP4'

save_path = '/content/drive/MyDrive/Vision/Huckelberry/March_1'
```

```{python}
#| id: eRenOxRNAT7V
#| id: eRenOxRNAT7V
cap = cv2.VideoCapture(video_path)
```

Here is a frame of this video

```{python}
#| id: Yek8C02ZA2B4
#| colab: {base_uri: 'https://localhost:8080/', height: 829}
#| id: Yek8C02ZA2B4
#| outputId: b401adab-1a90-4fd9-c481-c438658ec406
cap.set(cv2.CAP_PROP_POS_MSEC,500000)
hasFrames,image0 = cap.read()

print("The size of the frame : ", image0.shape)
cv2_imshow(image0)
```

```{python}
#| id: nEH02OuWAW3-
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: nEH02OuWAW3-
#| outputId: 7c1f18c2-b345-4b21-bd06-e9d3dad35603
fps = cap.get(cv2.CAP_PROP_FPS)
print("Frame rate of the video is : ", fps)
```

```{python}
#| id: IM8qIxsaCOXw
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: IM8qIxsaCOXw
#| outputId: 6e48b61b-c3af-43d0-f865-3cc6c4e7714f
clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)
print("Clip duration : {} (s)".format(clip_duration))
```

Since processing 30 frames per second is too demanding, we need to resample the video to reduce computation time while still maintaining satisfactory spatial resolution. We opted for 10 fps

```{python}
#| id: FP2zNtRPL5DW
#| id: FP2zNtRPL5DW
sp = 1 / 10
```

Each frame captures a wide range of views. To enhance precision, only a specific section of the image will be analyzed, while the rest will be ignored.

```{python}
#| id: EaxcoI5fPFov
#| colab: {base_uri: 'https://localhost:8080/', height: 1000}
#| id: EaxcoI5fPFov
#| outputId: ed5f4bbc-432a-4af5-a168-8c8446697261
cv2_imshow(image0[:, int(image0.shape[1]/2-100):int(image0.shape[1]/2+100)])
```

In this block all the frames will be shrinked by the factor of 1/10

```{python}
#| id: bfJMZ3kMCHJj
#| colab: {base_uri: 'https://localhost:8080/', height: 36}
#| id: bfJMZ3kMCHJj
#| outputId: 24d3074b-165b-44a1-f3b4-91cb7630ba9e
save_path
```

```{python}
#| id: CvR9ubjbrd16
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: CvR9ubjbrd16
#| outputId: 0da8d18a-fe2c-41eb-b9c0-3e4f27c5e9f8
clip = mp.VideoFileClip(video_path)

my_width = image0.shape[0]//10
my_height = image0.shape[1]//10

clip_resized = clip.resize(newsize=(my_width,my_height))
clip_resized.write_videofile(save_path + '/resized_video/1334_resized.MP4')
```

# Framing

```{python}
#| id: 5q40QQZ3mTlW
#| id: 5q40QQZ3mTlW
video_path = save_path + '/resized_video/1334_resized.MP4' # reduced-size video path
```

```{python}
#| id: VH7uhdRxmucu
#| colab: {base_uri: 'https://localhost:8080/', height: 548}
#| id: VH7uhdRxmucu
#| outputId: 6c3be71f-e435-4d07-f48c-1c355b1d0450
cap = cv2.VideoCapture(video_path)
cap.set(cv2.CAP_PROP_POS_MSEC,500000)
hasFrames,image0 = cap.read()

cv2_imshow(image0[:, int(image0.shape[1]/2-10):int(image0.shape[1]/2+10)])
```

# Save the frames

In this block all the frames will be saved as seperate images for easier future use. The name of each frame will be: Index_"frame number".jpg

```{python}
#| id: xDCnBkiEJ1sa
#| id: xDCnBkiEJ1sa
time = 0
img = []
t = []

c = 0
path = '/content/drive/MyDrive/Vision/Huckelberry/March_6/1334/10fps/Index_'

while (time+500)<clip_duration:
  cap.set(cv2.CAP_PROP_POS_MSEC,(time+500)*1000)
  hasFrames,image = cap.read()
  if hasFrames:
    image = image[:, int(image.shape[1]/2-10):int(image.shape[1]/2+10)]
    cv2.imwrite(path + str(c) + '.jpg', image)
    img.append(image)
    t.append(time)
    c = c + 1
  time += fps
```

```{python}
#| id: 0tu2HEydwsqb
#| id: 0tu2HEydwsqb
d = {'processed_images': img, 'time': t}
df = pd.DataFrame(data=d)
```

```{python}
#| id: nJcWEiZYxiSs
#| id: nJcWEiZYxiSs
df.to_csv('/content/drive/MyDrive/Track Buckling Project/230306 - Third Huckleberry Trail Test/GoPro/1334_resized.csv')
```

# Load the data

```{python}
#| id: s3thZPL3xjI7
#| id: s3thZPL3xjI7
df_new = pd.read_csv('/content/drive/MyDrive/Track Buckling Project/230306 - Third Huckleberry Trail Test/GoPro/1334_resized.csv')
```

```{python}
#| id: w4U5RkEG31aZ
#| colab: {base_uri: 'https://localhost:8080/', height: 423}
#| id: w4U5RkEG31aZ
#| outputId: 773e7273-fd99-4483-842f-4df7df2be2aa
df_new
```

```{python}
#| id: CYBhqVb0hRCS
#| id: CYBhqVb0hRCS
dirpath = '/content/drive/MyDrive/Vision/Huckelberry/March_6/1334/10fps/'
```

Reload the images and their respective index

```{python}
#| id: 0c_YKyTQKxJK
#| id: 0c_YKyTQKxJK
shots = []
idx = []

for i in range(0, df_new['time'].shape[0]):
  if os.path.exists(dirpath + 'Index_' + str(i) + '.jpg'):
    shots.append(cv2.imread(dirpath + 'Index_' + str(i) + '.jpg'))
    idx.append('Index_' + str(i))
  else:
    break
```

```{python}
#| id: oFsv_KKQoBEH
#| id: oFsv_KKQoBEH
df_new['image_index'] = idx
df_new['processed_images'] = shots
```

```{python}
#| id: _4gsnppojGZD
#| colab: {base_uri: 'https://localhost:8080/', height: 423}
#| id: _4gsnppojGZD
#| outputId: 73f15440-adbd-4499-b7a3-3c86025dcff5
df_new
```

# Training

## Labeling

Before training the model, we need to manually label the images. For this purpose, a section of the dataset is chosen and labeled. The indices for all the ties in that specific section are saved in the following dataframe.

```{python}
#| id: wWoji2ddp--e
#| id: wWoji2ddp--e
#| colab: {base_uri: 'https://localhost:8080/', height: 1000}
#| outputId: fa20f3ee-708a-4017-bdd4-fda3e0d92e05
tie_index = pd.read_excel('/content/drive/MyDrive/Vision/Huckelberry/March_6/1334/10fps/Training/tie_index.xlsx')
tie_index
```

```{python}
#| id: Fijd40Bl6ODN
#| id: Fijd40Bl6ODN
label = np.zeros(df_new['image_index'].shape[0])
```

```{python}
#| id: OV6c8UFV8adp
#| id: OV6c8UFV8adp
for i in tie_index['tie_index']:
  label[i] = 1

df_new['labels'] = label
```

```{python}
#| id: WhKhKmsY9Gcn
#| colab: {base_uri: 'https://localhost:8080/', height: 423}
#| id: WhKhKmsY9Gcn
#| outputId: 164819f3-ad6e-4aea-ab35-ced9d6af6b8b
df_new
```

```{python}
#| id: oUd8w9JI9IEG
#| colab: {base_uri: 'https://localhost:8080/', height: 423}
#| id: oUd8w9JI9IEG
#| outputId: 3e93d715-d5a4-4c48-aceb-bc38121824e8
df_train = df_new[(df_new['Unnamed: 0']>=47) & (df_new['Unnamed: 0']<=193)]
df_train
```

Defining the features

```{python}
#| id: Jhg0ENRlbTwM
#| id: Jhg0ENRlbTwM
features = []

for i in range(0, len(df_train['processed_images'])):
  features.append(np.array(cv2.resize(df_train.iloc[i]['processed_images'], (100, 500))))
```

```{python}
#| id: _4bUaSpHePQh
#| id: _4bUaSpHePQh
features = np.array(features)
```

Defining the labels

```{python}
#| id: XF3tMjflFISQ
#| id: XF3tMjflFISQ
labels = df_train['labels']
```

Normalizing the features

```{python}
#| id: AMbdNDwzeqkE
#| id: AMbdNDwzeqkE
features = features.astype('float32') / 255.0
```

## Train/Test Split

```{python}
#| id: 12gVntKTFB7s
#| id: 12gVntKTFB7s
train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size=0.2, stratify=labels)
```

According to the block below we have 117 data points in training set and 30 data points in test set

```{python}
#| id: FpXvuNwHFWZu
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: FpXvuNwHFWZu
#| outputId: fd44e87e-95e3-4126-e23a-9ff5c7ac412d
print(train_x.shape)
print(train_y.shape)
print(test_x.shape)
print(test_y.shape)
```

```{python}
#| id: KNDpG3DhG0Cq
#| id: KNDpG3DhG0Cq
from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model, Sequential
from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Dense
```

## Importing Inception V3

```{python}
#| id: iznG4hbFLCL-
#| id: iznG4hbFLCL-
base_model = InceptionV3(weights='imagenet', include_top=False,input_shape=(train_x.shape[1],train_x.shape[2],train_x.shape[3]))
for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)

Imported_model = Model(inputs=base_model.input, outputs=predictions)
```

```{python}
#| id: AE_ea_fsiQIc
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: AE_ea_fsiQIc
#| outputId: 35415d3c-f6cd-48eb-b3d4-7937b050f738
Imported_model.summary()
```

Adam is our optimizer and binary_crossentropy is the loss function

```{python}
#| id: 979gLT5SLUl6
#| id: 979gLT5SLUl6
Imported_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
```

```{python}
#| id: eMnmJ5A5f9Lz
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: eMnmJ5A5f9Lz
#| outputId: 82754f01-32fb-464a-d5ae-317e6d9b97b9
Imported_model.fit(train_x, train_y, epochs = 5, batch_size = 256, verbose=1, validation_data=(test_x, test_y))
```

## Save / Load the model

```{python}
#| id: FC6HGPEOf_Z8
#| id: FC6HGPEOf_Z8
Imported_model.save('/content/drive/MyDrive/Vision/Huckelberry/March_6/1334/10fps/Training/myModel.h5')
#Imported_model.save_weights("myModel2.h5", '/content/drive/MyDrive/Vision/Huckelberry/March_6/1334/10fps/Training')
```

```{python}
#| id: YFvMmD5uigRJ
#| id: YFvMmD5uigRJ
from keras.models import load_model
Imported_model = load_model('/content/drive/MyDrive/Vision/Huckelberry/March_6/1334/10fps/Training/myModel.h5')
#new_model.load_weights("myModel2.h5")
```

# Test over two unseen image

```{python}
#| id: hna0i0wfkIJs
#| id: hna0i0wfkIJs
tie_pred = cv2.imread('/content/drive/MyDrive/Vision/Huckelberry/March_6/1334/10fps/Index_237.jpg')
tie_pred = cv2.resize(tie_pred, (100, 500))

bal_pred = cv2.imread('/content/drive/MyDrive/Vision/Huckelberry/March_6/1334/10fps/Index_241.jpg')
bal_pred = cv2.resize(bal_pred, (100, 500))
```

```{python}
#| id: PqBoDx_HlmE5
#| colab: {base_uri: 'https://localhost:8080/', height: 1000}
#| id: PqBoDx_HlmE5
#| outputId: e46be128-9f05-4b3e-ddb1-9638d7582e0d
cv2_imshow(tie_pred)
cv2_imshow(bal_pred)
```

```{python}
#| id: OrIDp5uKlpDT
#| id: OrIDp5uKlpDT
tie_pred = tie_pred.astype('float32') / 255.0
bal_pred = bal_pred.astype('float32') / 255.0
```

```{python}
#| id: T6Rgkmrfl2eS
#| id: T6Rgkmrfl2eS
tie_pred = np.array(tie_pred)
bal_pred = np.array(bal_pred)

tie_pred = np.expand_dims(tie_pred, axis=0)
bal_pred = np.expand_dims(bal_pred, axis=0)
```

```{python}
#| id: OfGzkYEol-hm
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: OfGzkYEol-hm
#| outputId: 5290d71a-abbc-482d-a22f-cde7e28f6cc1
print("Probability of a ballast image to be tie : ",Imported_model.predict(bal_pred))
```

```{python}
#| id: y0xh8GE3mFh6
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: y0xh8GE3mFh6
#| outputId: d96ff070-ca9b-4ce4-e97e-584e0543c1c4
print("Probability of a tie image to be tie : ",Imported_model.predict(tie_pred))
```

# Do the prediction over the entire dataset

```{python}
#| id: uEb7rQQ2wjtU
#| id: uEb7rQQ2wjtU
prediction = []

for i in range(0, len(df_new['processed_images'])):
  prediction.append(np.array(cv2.resize(df_new.iloc[i]['processed_images'], (100, 500))))
```

```{python}
#| id: 0hCE7hYu1ef1
#| id: 0hCE7hYu1ef1
prediction = np.array(prediction)
```

```{python}
#| id: SI7C0oTF1qXx
#| id: SI7C0oTF1qXx
prediction = prediction.astype('float32') / 255.0
```

```{python}
#| id: jwS7J17q1vKj
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: jwS7J17q1vKj
#| outputId: e8b60c46-852f-4d7d-d11b-2d4208d71d4f
pred_label = Imported_model.predict(prediction)
```

If the predicted probability is                          

*   > 0.75 : Ties
*   < 0.25 : Ballast
*   in between : ambiguous


```{python}
#| id: CJKPlefe2Ap9
#| id: CJKPlefe2Ap9
final_label = []

for i in range(0, len(pred_label)):
  if pred_label[i]>=0.75:
    final_label.append('T')
  if pred_label[i]<=0.25:
    final_label.append('B')
  if (pred_label[i]>0.25) & (pred_label[i]<0.75):
    final_label.append('A')
```

```{python}
#| id: sh79oom94mwE
#| colab: {base_uri: 'https://localhost:8080/', height: 423}
#| id: sh79oom94mwE
#| outputId: 35c585be-b267-4536-e988-63e23ce3e64d
df_new['Predicted_labels'] = final_label
df_new
```

