---
title: Lubricity detection using Computer Vision
jupyter: python3
---


In this project, a camera was mounted on a rail cart targeted the gage face of the rail. The recorded videos then were processed to autonomously identify lubricated sections


```{python}
#| id: GsUts0CFF1WT
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: GsUts0CFF1WT
#| outputId: c2fdc267-d79f-4e15-fada-6a41509ae6aa
from google.colab import drive
drive.mount('/content/drive')
```

```{python}
#| id: KTHSBaqgISI2
#| id: KTHSBaqgISI2
def interactive_plot_scatter(df, x_axis, y_axis, xlabel, ylabel):
  import plotly.express as px

  fig = px.scatter(df, x_axis, y_axis).update_layout(xaxis_title=xlabel, yaxis_title=ylabel)

  return fig.show()

def interactive_plot_line(df, x_axis, y_axis, xlabel, ylabel):
  import plotly.express as px

  fig = px.line(df, x_axis, y_axis).update_layout(xaxis_title=xlabel, yaxis_title=ylabel)

  return fig.show()
```

```{python}
#| id: xtGsH8dOF6mn
#| id: xtGsH8dOF6mn
!pip install moviepy

!pip3 install imageio==2.4.1

!pip install --upgrade imageio-ffmpeg
```

```{python}
#| id: WTHvXv1nGBu2
#| id: WTHvXv1nGBu2
import moviepy.editor as mp
```

```{python}
#| id: 18UQLyu9GHqX
#| id: 18UQLyu9GHqX
import cv2
import os
import numpy as np
import pandas as pd
from google.colab.patches import cv2_imshow
from numpy import genfromtxt
from PIL import Image
import os
```

```{python}
#| id: 4jVYhQQSfDNd
#| id: 4jVYhQQSfDNd
from moviepy.editor import *
```

```{python}
#| id: u1AZlQCa1EBH
#| id: u1AZlQCa1EBH
Test = 'Test_1'
Camera = 'A'
Encoder = 'MP4'
```

```{python}
#| id: oeYArfECaHQA
#| id: oeYArfECaHQA
video_path = '/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/' + Test + '/' + Test + '_' + Camera + '.' + Encoder
save_path = '/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/' + Test +'/Reduced_size/' + Test + '_' + Camera + '.' + Encoder
```

# Find bounds

```{python}
#| id: UZ5JUGDpZohK
#| id: UZ5JUGDpZohK
def Find_bounds(video_path, time, X_low, X_high, Y_low, Y_high):
  cap = cv2.VideoCapture(video_path)
  clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)

  cap.set(cv2.CAP_PROP_POS_MSEC,time*1000)
  hasFrames,image1 = cap.read()

  image0 = image1[X_low:X_high, Y_low:Y_high]

  # cv2_imshow(image1)
  # cv2_imshow(image0)
  return image1, image0
```

By trial and error, coordinates of the target were identified. Now we can crop the images to get rid of redundant parts of the image. This would dramatically reduce the computation cost.

```{python}
#| id: sQyTS0JcamnC
#| colab: {background_save: true, base_uri: 'https://localhost:8080/', height: 1000}
#| id: sQyTS0JcamnC
#| outputId: 6ede7c56-2256-4be0-8628-07629bd4a12d
time = 40

cap = cv2.VideoCapture(video_path)
cap.set(cv2.CAP_PROP_POS_MSEC,time*1000)
hasFrames,image1 = cap.read()

X_low = int(image1.shape[0]/2-125)
X_high = int(image1.shape[0]/2+25)
Y_low = int(image1.shape[1]/2-75)
Y_high = int(image1.shape[1]/2+75)

image1, image0 = Find_bounds(video_path, time, X_low, X_high, Y_low, Y_high)

cv2_imshow(image0)
cv2_imshow(image1)
```

# Reduce Size

In this section we reduce the image sizes to lower the computation cost

```{python}
#| id: QjVOt7pvX1jp
#| id: QjVOt7pvX1jp
def reduce_size(video_path, save_path, Start_Time, End_Time):
  cap = cv2.VideoCapture(video_path)
  clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)
  clip = VideoFileClip(video_path).subclip(Start_Time, End_Time)

  my_width = image1.shape[1]//2
  my_height = image1.shape[0]//2

  clip_resized = clip.resize(newsize=(my_width, my_height))
  clip_resized.write_videofile(save_path)
```

```{python}
#| id: Hc4tzxjGg6eI
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: Hc4tzxjGg6eI
#| outputId: 7853f29b-485a-40fe-ca9d-a888adba81ec
reduce_size(video_path, save_path, Start_Time = 4*60 + 47, End_Time = 10*60 + 17)
```

# Framing

In this section the videos were divided intp frames and saved as images.

```{python}
#| id: QneRg8mOdYd4
#| id: QneRg8mOdYd4
video_path = save_path
```

```{python}
#| id: c2HHaTf37kWZ
#| colab: {base_uri: 'https://localhost:8080/', height: 35}
#| id: c2HHaTf37kWZ
#| outputId: 08d0bde9-c1c2-4d5c-8a95-71931448f6c6
video_path
```

```{python}
#| id: iur1faxiffGL
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: iur1faxiffGL
#| outputId: 138223c2-6d89-4262-cce2-00d443b0c0b2
cap = cv2.VideoCapture(video_path)

clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)
clip_duration
```

```{python}
#| id: nWT3sSu0ffgo
#| colab: {base_uri: 'https://localhost:8080/', height: 574}
#| id: nWT3sSu0ffgo
#| outputId: aa6ed1f8-7641-48cc-8428-7dd7a0908776
cap.set(cv2.CAP_PROP_POS_MSEC, 2)
hasFrames,image0 = cap.read()

#cv2_imshow(image0[int(X_low/2):int(X_high/2), int(Y_low/2):int(Y_high/2)])
cv2_imshow(image0)
image0.shape
```

```{python}
#| id: x2xEEeKhfmTo
#| id: x2xEEeKhfmTo
time = 0.00
img = []
t = []
fps = 1 / 10

while (time)<clip_duration:
  cap.set(cv2.CAP_PROP_POS_MSEC,time*1000)
  hasFrames,image0 = cap.read()
  if hasFrames:
    image = image0[int(X_low/2):int(X_high/2), int(Y_low/2):int(Y_high/2)]
    img.append(image)
    t.append(time)
    print(time)
  time = round(time + fps, 2)
```

```{python}
#| id: ZIX_GtaHgqoz
#| colab: {base_uri: 'https://localhost:8080/', height: 92}
#| id: ZIX_GtaHgqoz
#| outputId: c5487c05-6ba3-4b69-f690-9c006a551958
from google.colab.patches import cv2_imshow

cv2_imshow(img[1000])
```

# Save the frames

```{python}
#| id: 8QXj8Nt7g1lg
#| id: 8QXj8Nt7g1lg
c = 0
index = []
time0 = time

for i in t:
  path = '/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/Cropped_frames_Camera_C/Index_' + str(c) + '.jpg'
  cv2.imwrite(path, img[c])
  index.append('Index_' + str(c))
  print(i)
  c = c + 1
```

```{python}
#| id: bqAdh8Cqk0e4
#| id: bqAdh8Cqk0e4
d = {'Image_index': index, 'time': t}
df = pd.DataFrame(data=d)
```

```{python}
#| id: 6_9ZNcjwldkn
#| id: 6_9ZNcjwldkn
df.to_csv('/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/index-time_Test1C.csv')
```

# Load the data

```{python}
#| id: erJXoZfzlp-g
#| id: erJXoZfzlp-g
df_new = pd.read_csv('/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/index-time_Test1A.csv')
```

```{python}
#| id: yMwbMRoN469I
#| colab: {base_uri: 'https://localhost:8080/', height: 424}
#| id: yMwbMRoN469I
#| outputId: 1e60ebbe-ccd7-4a14-a351-c5f1635336a8
df_new
```

```{python}
#| id: 0nyT8imp493J
#| id: 0nyT8imp493J
dirpath = '/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/Cropped_frames_Test_1_A/'
```

```{python}
#| id: Fh5uaPwv5DWa
#| id: Fh5uaPwv5DWa
shots = []
idx = []

for i in range(0, df_new['time'].shape[0]):
  if os.path.exists(dirpath + 'Index_' + str(i) + '.jpg'):
    shots.append(cv2.imread(dirpath + 'Index_' + str(i) + '.jpg'))
    idx.append('Index_' + str(i))
  else:
    break
```

```{python}
#| id: WNoONdJB5dqS
#| id: WNoONdJB5dqS
df_new['image_index'] = idx
df_new['processed_images'] = shots
```

```{python}
#| id: pW5ZeDbM5hex
#| colab: {base_uri: 'https://localhost:8080/', height: 424}
#| id: pW5ZeDbM5hex
#| outputId: a2296d6d-c164-4114-db7c-f40b30f1a68a
df_new
```

# Training

## Auto Labeling

Two sections of the video were lubricated. We manually labeled part of them for training

```{python}
#| id: qNShbXq1ea7e
#| id: qNShbXq1ea7e
L = [886, 1379, 1792, 2809]     # L = ['Start of Lubrication' : index number, 'End of Lubrication' : index number, /////]
endpoint = len(df_new)
step = 10

labels = np.ones(endpoint) * (-1)

for i in range(0, endpoint, step):
  labels[i] = 0
  for j in range(int(len(L) / 2)):
    if (df_new.iloc[i]['Unnamed: 0']>L[j*2]) and (df_new.iloc[i]['Unnamed: 0']<L[j*2+1]):
      labels[i] = 1

df_new['labels'] = labels
```

```{python}
#| id: f4ooV9fm7jYB
#| colab: {base_uri: 'https://localhost:8080/', height: 424}
#| id: f4ooV9fm7jYB
#| outputId: 988f52b8-68b7-42dd-f584-99137b26d030
df_train = df_new[df_new['labels'] != -1]
df_train
```

```{python}
#| id: Tiaw_oUV-Nah
#| id: Tiaw_oUV-Nah
features = []

for i in range(0, len(df_train['processed_images'])):
  features.append(np.array(df_train.iloc[i]['processed_images']))
```

```{python}
#| id: 9lHhXGyU-bnJ
#| id: 9lHhXGyU-bnJ
features = np.array(features)
```

```{python}
#| id: hWZJAs3n-dQK
#| id: hWZJAs3n-dQK
labels = df_train['labels']
```

```{python}
#| id: TY0F_sdq-hy5
#| id: TY0F_sdq-hy5
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
```

```{python}
#| id: SlbTZfp5-jiR
#| id: SlbTZfp5-jiR
features = features.astype('float32') / 255.0
```

```{python}
#| id: 2U3xOw0h-lbK
#| id: 2U3xOw0h-lbK
train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size=0.2, stratify=labels)
```

```{python}
#| id: QFX0_p09-nuq
#| id: QFX0_p09-nuq
train_x, train_y = shuffle(train_x, train_y, random_state=0)
test_x, test_y = shuffle(test_x, test_y, random_state=0)
```

```{python}
#| id: dkOv0qa__b16
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: dkOv0qa__b16
#| outputId: 366c2055-390e-4257-d0f2-176bd0ae7b49
print(train_x.shape)
print(train_y.shape)
print(test_x.shape)
print(test_y.shape)
```

```{python}
#| id: Z4lsf_Y0_vbS
#| id: Z4lsf_Y0_vbS
from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model, Sequential
from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Dense
```

```{python}
#| id: tPmJwjIP_yz6
#| id: tPmJwjIP_yz6
base_model = InceptionV3(weights='imagenet', include_top=False,input_shape=df_train.iloc[0]['processed_images'].shape)
for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)

Imported_model = Model(inputs=base_model.input, outputs=predictions)
```

```{python}
#| id: W_FUaKNC_6Mh
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: W_FUaKNC_6Mh
#| outputId: 191e6fba-1e3b-4c0e-ffe8-fa243c2850dc
Imported_model.summary()
```

```{python}
#| id: ekO7h4qR_9dx
#| id: ekO7h4qR_9dx
Imported_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
```

```{python}
#| id: SFQHVCOMABES
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: SFQHVCOMABES
#| outputId: d3516a8e-289a-4a38-ac7f-23812fb72dc9
Imported_model.fit(train_x, train_y, epochs = 7, batch_size = 256, verbose=1, validation_data=(test_x, test_y))
```

```{python}
#| id: iSQ9sgR0ADBr
#| id: iSQ9sgR0ADBr
saveLoadpath = '/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/'

Imported_model.save(saveLoadpath + 'Test_1_A.h5')
```

```{python}
#| id: I-gdIO6K23C1
#| id: I-gdIO6K23C1
saveLoadpath = '/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/'

from keras.models import load_model
Imported_model = load_model(saveLoadpath + 'Test_1_A.h5')
```

# Validation

Two images which have not been used in training the model are now imported to verfy the model's accuracy

```{python}
#| id: QSDsLRrm3VK0
#| id: QSDsLRrm3VK0
lub_pred = cv2.imread('/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/Cropped_frames_Test_1_A/Index_2019.jpg')
lub_pred = cv2.resize(lub_pred, (100,100))

ul_pred = cv2.imread('/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/Cropped_frames_Test_1_A/Index_862.jpg')
ul_pred = cv2.resize(ul_pred, (100,100))
```

```{python}
#| id: txzOceUD371P
#| colab: {base_uri: 'https://localhost:8080/', height: 217}
#| id: txzOceUD371P
#| outputId: 7c614cbb-ef0b-4e52-82b4-1a251ffabb57
cv2_imshow(lub_pred)
cv2_imshow(ul_pred)
```

```{python}
#| id: z-Gcv9J14AtT
#| id: z-Gcv9J14AtT
lub_pred = lub_pred.astype('float32') / 255.0
ul_pred = ul_pred.astype('float32') / 255.0
```

```{python}
#| id: 3QYnKKT34QdT
#| id: 3QYnKKT34QdT
lub_pred = np.array(lub_pred)
ul_pred = np.array(ul_pred)

lub_pred = np.expand_dims(lub_pred, axis=0)
ul_pred = np.expand_dims(ul_pred, axis=0)
```

```{python}
#| id: A-ftAqOi4WIz
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: A-ftAqOi4WIz
#| outputId: d3c45067-9da9-46a1-c0e8-990bf7b060ae
print(Imported_model.predict(lub_pred))
```

```{python}
#| id: Ah8rdhvD4ZSm
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: Ah8rdhvD4ZSm
#| outputId: 5e1f6171-1dd4-480c-ed90-57308a0235c6
print(Imported_model.predict(ul_pred))
```

Now, we do the prediction over the entire data

```{python}
#| id: WxD9_rM94k_k
#| id: WxD9_rM94k_k
prediction = []

for i in range(0, len(df_new['processed_images'])):
  prediction.append(np.array(cv2.resize(df_new.iloc[i]['processed_images'], df_new.iloc[0]['processed_images'].shape[0:2])))
```

```{python}
#| id: SHufe1wp4zeV
#| id: SHufe1wp4zeV
prediction = np.array(prediction)
```

```{python}
#| id: E9YUMUis40sN
#| id: E9YUMUis40sN
prediction = prediction.astype('float32') / 255.0
```

```{python}
#| id: dJxcMkO242Jm
#| colab: {base_uri: 'https://localhost:8080/'}
#| id: dJxcMkO242Jm
#| outputId: 5b89eb5c-1572-444c-9d54-aaa5276689c2
pred_label = Imported_model.predict(prediction)
```

```{python}
#| id: b6DNUfBT43vl
#| id: b6DNUfBT43vl
final_label = []

for i in range(0, len(pred_label)):
  if pred_label[i]>=0.6:
    final_label.append(1)
  if pred_label[i]<=0.4:
    final_label.append(0)
  if (pred_label[i]>0.4) & (pred_label[i]<0.6):
    final_label.append(-1)
```

```{python}
#| id: R_ucBR7XGnXv
#| id: R_ucBR7XGnXv
time = 16
imgt = []
t = []
fps = 1 / 10

cap = cv2.VideoCapture(video_path)
clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)

while (time)<clip_duration:
  cap.set(cv2.CAP_PROP_POS_MSEC,time*1000)
  hasFrames,image0 = cap.read()
  if hasFrames:
    image = image0
    imgt.append(image)
    t.append(time)
  time += fps

shots = imgt
```

```{python}
#| id: O8t3T_xQ5Arm
#| id: O8t3T_xQ5Arm
shots = []
idx = []

for i in range(0, df_new['time'].shape[0]):
  if os.path.exists(dirpath + 'Index_' + str(i) + '.jpg'):
    shots.append(cv2.imread(dirpath + 'Index_' + str(i) + '.jpg'))
    idx.append('Index_' + str(i))
  else:
    break
```

```{python}
#| id: lZDaH6JT5K-i
#| id: lZDaH6JT5K-i
df_new['Predicted_labels'] = final_label
```

```{python}
#| id: ahmCFAyHG2tl
#| colab: {base_uri: 'https://localhost:8080/', height: 424}
#| id: ahmCFAyHG2tl
#| outputId: dda118e0-526e-4d4a-b99c-f62628f2f132
df_new
```

```{python}
#| id: bezwQdLRIkOv
#| colab: {base_uri: 'https://localhost:8080/', height: 542}
#| id: bezwQdLRIkOv
#| outputId: 9f85cfeb-34f7-42f6-80c9-60db00e6a146
interactive_plot_scatter(df_new, 'time', 'Predicted_labels', xlabel="Time(s)", ylabel="Lubrication")
```

```{python}
#| id: 2J2ZZaDbOTzX
#| id: 2J2ZZaDbOTzX
df_new.to_csv('/content/drive/MyDrive/RTL_Lubricity/Machine_Vision/Hucklebery/6_8_2023/Test_1/Predicted_Test1A.csv')
```

